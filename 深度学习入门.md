# 深度学习入门



```python
import tensorflow.keras as keras
import pandas as pd

# Load in our data from CSV files
train_df = pd.read_csv("data/asl_data/sign_mnist_train.csv")
valid_df = pd.read_csv("data/asl_data/sign_mnist_valid.csv")

# Separate out our target values
y_train = train_df['label']
y_valid = valid_df['label']
del train_df['label']
del valid_df['label']

# Separate out our image vectors
x_train = train_df.values
x_valid = valid_df.values

# Turn our scalar targets into binary categories
num_classes = 24
y_train = keras.utils.to_categorical(y_train, num_classes)
y_valid = keras.utils.to_categorical(y_valid, num_classes)

# y_train 和 y_valid 是训练集和验证集的目标标量，即原始的类别标签。通过使用 Keras 提供的 to_categorical 函数，将这些标量目标转换为二进制类别形式的独热编码。num_classes 是类别的数量，用于确定独热编码的长度。

# 转换后，y_train 和 y_valid 中的每个标量目标将被表示为一个长度为 num_classes 的二进制向量，其中只有对应类别位置的元素为1（表示属于该类别），其他位置的元素为0。这样的码方式可以对目标进行更好地表示和处理，用于神经网络的训练和评估。

# Normalize our image data
x_train = x_train / 255
x_valid = x_valid / 255
```

### 独热编码（One-Hot Encoding）

是一种常用的将离散特征表示为二进制向量的方法。在机器学习和深度学习中，独热编码被广泛应用于处理分类特征。

独热编码基本思想是将每个离散特征的取值映射为一个唯一的二进制向量，其中只有一个元素为1，其他元素为0。这样可以将离散特征的不同取值转换为不同的向量，从而方便计算机处理和理解。

具体来说，假设有一个离散特征，有k个不同的取值，独热编码的过程为：

1. 创建一个长度为k的二进制向量，所有元素初始化为0。
2. 将对应的取值索引位置的元素设置为1。

例如，假设有一个特征"颜色"，可能的取值有"红"、“蓝"和"绿”，那么独热编码的结果如下：

- "红 = [1, 0, 0]
- “蓝” = [0, 1, 0]
- “绿” = [0, 0, 1]

通过独热编码，将离散特征转换为二进制向量表示后，可以方便地用于机器学习算法和深度学习模型的训练和处理。独热编码可以避免特征之间的大小关系对模型造成的影响，同时能够更好地表示不同类别之间的关系。



##　创建卷积模型

```python
model = Sequential()
# 在深度学习中，`Sequential()` 是 Keras 库中的一个类，用于定义神经网络模型。它表示一个序列模型，即层按照顺序逐个堆叠在一起的方式构建神经网络。

# `model = Sequential()` 这行代码创建一个名为 `model` 的空的序列模型。我们可以通过向 `model` 中添加层来构建我们的神经网络。

# 例如，假设我们要构建一个简单的全连接神经网络，我们可以按照下面的步骤使用 `Sequential()` 构建：
'''
1. 创建一个 `Sequential` 对象：`model = Sequential()`
2. 添加输入层：`model.add(Dense(units=, input_dim=784))`
3. 添加隐藏层：`model.add(Dense(units=64, activation='relu'))`
4. 添加输出层：`model.add(Dense(units=10, activation='softmax'))`
'''

# 这样，我们就得到了一个具有输入层、隐藏层和输出层的神经网络模型。通过 `Sequential` 类，我们可以方便地按顺序组织各层，并指定每层的参数和激活函数等。

# 值得注意的是，`Sequential()` 适用于一些简单的、顺序堆叠的神经网络结构。对于一些更复杂的网络结构，例如存在多个输入/输出、跳跃连接等，可能需要使用 Keras 的函数式 API 来构建模型。
```

比如：

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Dense,
    Conv2D,
    MaxPool2D,
    Flatten,
    Dropout,
    BatchNormalization,
)

model = Sequential()
model.add(Conv2D(75, (3, 3), strides=1, padding="same", activation="relu", 
                 input_shape=(28, 28, 1)))
model.add(BatchNormalization())
model.add(MaxPool2D((2, 2), strides=2, padding="same"))
model.add(Conv2D(50, (3, 3), strides=1, padding="same", activation="relu"))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2, 2), strides=2, padding="same"))
model.add(Conv2D(25, (3, 3), strides=1, padding="same", activation="relu"))
model.add(BatchNormalization())
model.add(MaxPool2D((2, 2), strides=2, padding="same"))
model.add(Flatten())
model.add(Dense(units=512, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(units=num_classes, activation="softmax"))
```



### Conv2D

这些是 2D 卷积层。较小的内核将仔细检查输入图像并检测对分类十分重要的特征。模型中的前面几层卷积将检测简单的特征，例如线条。后续的卷积层将检测更复杂的特征。我们来看一下第一个 Conv2D 层：

```Python
model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same'...)
```

75 是指将要学习到的滤波器的数量。(3,3) 是指这些滤波器的大小。步长是指滤波器通过图像时的步进长度。填充是指从滤波器创建的输出图像是否与输入图像的大小匹配。

### BatchNormalization

如同对输入进行归一化一样，批量归一化可缩放隐藏层中的值以改善训练。如果愿意，您可在[此处阅读更多相关详细信息](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)。

### MaxPool2D

最大值池化层把经过它的图像缩小至较低分辨率。这样有助于增强模型对物体平移（对象左右移动）的鲁棒性，同时提升模型的训练速度。

### Dropout[¶](http://dli-604a4aa51b37-5cc147.aws.labs.courses.nvidia.com/lab/lab/tree/03_asl_cnn.ipynb#Dropout)

Dropout 是一种防止过拟合的技术。Dropout 随机选择一个神经元子集并在一次训练中将其关闭，使它们在该轮训练中不参与前向传播或反向传播。这有助于确保网络的鲁棒性和冗余性，使其不依赖网络中的任何区域来提供答案。

### Flatten

Flatten 接受某层的多维输出，并将其展平为一维数组。此层的输出称为特征向量，并将连接到最终分类层。

### Dense

在较早的模型中，我们已经见过密集层。我们的首个密集层（512 个单位）以特征向量作为输入，并学习到哪些特征对某个特定的分类贡献了多大的作用。第二个密集层（24 个单位）是输出预测的最终分类层。





```python
# Reshape the image data for the convolutional network
x_train = x_train.reshape(-1,28,28,1)
x_valid = x_valid.reshape(-1,28,28,1)
```

在机器学习和深度学习中，对数据进行预处理时，经常会使用 `-1` 这个特殊的参数。在 `reshape` 操作中，`-1` 的作用是自动计算该轴的大小，以确保总的元素数量不变。

具体来说，对于一个多维数组（比如图像数据），每个维度上的元素数量可能不同，但总的元素数量保持不变。当你使用 `-1` 作为某个维度的大小时，NumPy（或其他支持类似操作的库）会自动计算该维度的大小，以保持总的元素数量不变。

在你的例子中，`x_train` 和 `x_valid` 是图像数据，被表示成四维的数组（批次大小，图像高度，图像宽度，通道数）。当你使用 `reshape(-1, 28, 28, 1)` 时，这里的 `-1` 就是告诉 NumPy 根据总的元素数量自动计算批次大小，以确保总的元素数量不变。在这个过程中，28*28*1 就是每个图像的元素数量，而总的元素数量是批次大小乘以每个图像的元素数量。



